# ==============================================================================
# LLM Gateway - Hybrid Mode Overlay
# ==============================================================================
# Use with: docker-compose -f docker-compose.yml -f docker-compose.hybrid.yml up -d llm-gateway-standalone
#
# This overlay:
#   1. Removes the local Redis service (uses platform's ai-platform-redis)
#   2. Connects to ai-platform-network for infrastructure access
#   3. Points REDIS_URL to the platform's centralized Redis
#
# Prerequisites:
#   - ai-platform-data/docker infrastructure running (Neo4j, Qdrant, Redis)
#   - ai-platform-network must exist
# ==============================================================================

services:
  # Disable the local Redis - use platform's ai-platform-redis instead
  redis:
    profiles:
      - never  # This effectively disables the service

  # Override llm-gateway-standalone for hybrid mode
  llm-gateway-standalone:
    depends_on: {}  # Remove Redis dependency
    environment:
      LLM_GATEWAY_ENV: development
      LLM_GATEWAY_PORT: "8080"
      LLM_GATEWAY_LOG_LEVEL: DEBUG
      LLM_GATEWAY_WORKERS: "2"
      # Use platform's centralized Redis
      LLM_GATEWAY_REDIS_URL: redis://ai-platform-redis:6379
      # Host URLs for services running on host ports (macOS Docker Desktop)
      LLM_GATEWAY_SEMANTIC_SEARCH_URL: http://host.docker.internal:8081
      LLM_GATEWAY_AI_AGENTS_URL: http://host.docker.internal:8082
      LLM_GATEWAY_DEFAULT_PROVIDER: anthropic
      LLM_GATEWAY_DEFAULT_MODEL: claude-3-sonnet-20240229
      LLM_GATEWAY_RATE_LIMIT_REQUESTS_PER_MINUTE: "60"
      LLM_GATEWAY_SESSION_TTL_SECONDS: "3600"
    networks:
      - ai-platform-network  # Connect to platform network for Redis access

networks:
  ai-platform-network:
    external: true
