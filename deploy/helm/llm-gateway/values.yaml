# =============================================================================
# LLM Gateway - Helm Chart Default Values
# =============================================================================
# Override these values using --set or -f custom-values.yaml
#
# Example:
#   helm install llm-gateway ./deploy/helm/llm-gateway \
#     --set image.tag=v1.0.0 \
#     --set secrets.anthropicApiKey=sk-ant-xxx
# =============================================================================

# =============================================================================
# Image Configuration
# =============================================================================
image:
  repository: ghcr.io/kevin-toles/llm-gateway
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

# =============================================================================
# Replica Configuration
# =============================================================================
replicaCount: 2

# =============================================================================
# ServiceAccount Configuration
# =============================================================================
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
    # AWS IRSA example:
    # eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/llm-gateway-role
    # GCP Workload Identity example:
    # iam.gke.io/gcp-service-account: llm-gateway@PROJECT.iam.gserviceaccount.com
  # The name of the service account to use
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# =============================================================================
# Pod Annotations
# =============================================================================
podAnnotations:
  # Prometheus scraping
  prometheus.io/scrape: "true"
  prometheus.io/port: "8080"
  prometheus.io/path: "/metrics"

podLabels: {}

# =============================================================================
# Pod Security Context
# =============================================================================
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

# =============================================================================
# Container Security Context
# =============================================================================
securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  capabilities:
    drop:
      - ALL

# =============================================================================
# Service Configuration
# =============================================================================
service:
  type: ClusterIP
  port: 8080
  # nodePort: 30080  # Only used when type is NodePort
  annotations: {}

# =============================================================================
# Ingress Configuration
# =============================================================================
ingress:
  enabled: false
  className: "nginx"
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    # cert-manager.io/cluster-issuer: letsencrypt-prod
  hosts:
    - host: llm-gateway.local
      paths:
        - path: /
          pathType: Prefix
  tls: []
  #  - secretName: llm-gateway-tls
  #    hosts:
  #      - llm-gateway.local

# =============================================================================
# Resource Requests and Limits
# =============================================================================
resources:
  requests:
    cpu: "250m"
    memory: "512Mi"
  limits:
    cpu: "1000m"
    memory: "2Gi"

# =============================================================================
# Autoscaling Configuration
# =============================================================================
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
    scaleUp:
      stabilizationWindowSeconds: 0

# =============================================================================
# Pod Disruption Budget
# =============================================================================
podDisruptionBudget:
  enabled: true
  minAvailable: 1
  # maxUnavailable: 1

# =============================================================================
# Node Selector, Tolerations, Affinity
# =============================================================================
nodeSelector: {}

tolerations: []

affinity: {}
  # podAntiAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #     - weight: 100
  #       podAffinityTerm:
  #         labelSelector:
  #           matchLabels:
  #             app.kubernetes.io/name: llm-gateway
  #         topologyKey: kubernetes.io/hostname

# =============================================================================
# Probes Configuration
# =============================================================================
livenessProbe:
  httpGet:
    path: /live
    port: http
  initialDelaySeconds: 30
  periodSeconds: 30
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: http
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 5
  failureThreshold: 30

# =============================================================================
# Application Configuration
# =============================================================================
config:
  # Environment (development, staging, production)
  environment: "production"
  
  # Logging level (DEBUG, INFO, WARNING, ERROR)
  logLevel: "INFO"
  
  # Number of Uvicorn workers
  workers: 4
  
  # Default LLM provider (anthropic, openai, ollama)
  defaultProvider: "anthropic"
  
  # Default model
  defaultModel: "claude-3-sonnet-20240229"
  
  # Rate limiting
  rateLimitRequestsPerMinute: 60
  rateLimitTokensPerMinute: 100000
  
  # Session configuration
  sessionTtlSeconds: 3600
  maxContextLength: 128000
  
  # Service discovery URLs (when not using Redis/internal services)
  # Leave empty to use in-cluster DNS
  semanticSearchUrl: ""
  aiAgentsUrl: ""
  ollamaBaseUrl: ""
  
  # External Redis URL (when redis.enabled=false)
  redisUrl: ""

# =============================================================================
# Secrets Configuration
# =============================================================================
# IMPORTANT: Do not commit actual values to version control!
# Use external secret management (External Secrets, Sealed Secrets, etc.)
secrets:
  # Create a Kubernetes Secret with API keys
  create: true
  
  # Name of existing secret to use (if create=false)
  existingSecret: ""
  
  # API Keys (base64 encoded when using create=true)
  # Override at install time: --set secrets.anthropicApiKey=sk-ant-xxx
  anthropicApiKey: ""
  openaiApiKey: ""
  
  # External Secrets configuration
  externalSecrets:
    enabled: false
    secretStoreRef:
      name: ""
      kind: "ClusterSecretStore"
    remoteRefs:
      anthropicApiKey: ""
      openaiApiKey: ""

# =============================================================================
# Network Policy Configuration
# =============================================================================
networkPolicy:
  enabled: true
  
  # Ingress rules
  ingress:
    # Allow from ingress controller
    allowIngressController: true
    ingressControllerNamespace: "ingress-nginx"
    
    # Allow from monitoring namespace
    allowMonitoring: true
    monitoringNamespace: "monitoring"
    
    # Additional ingress rules
    additionalRules: []
  
  # Egress rules
  egress:
    # Allow DNS
    allowDns: true
    
    # Allow external HTTPS (for LLM APIs)
    allowExternalHttps: true
    
    # Allow Redis
    allowRedis: true
    
    # Additional egress rules
    additionalRules: []

# =============================================================================
# Redis Subchart Configuration (Bitnami)
# =============================================================================
redis:
  # Enable Redis subchart deployment
  enabled: true
  
  # Redis architecture (standalone or replication)
  architecture: standalone
  
  # Authentication
  auth:
    enabled: false
    # password: ""
  
  # Master configuration
  master:
    persistence:
      enabled: true
      size: 1Gi
    resources:
      requests:
        cpu: "100m"
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "512Mi"
  
  # Replica configuration (only when architecture=replication)
  replica:
    replicaCount: 0

# =============================================================================
# Extra Volumes and Volume Mounts
# =============================================================================
extraVolumes:
  - name: tmp
    emptyDir:
      sizeLimit: 100Mi
  - name: cache
    emptyDir:
      sizeLimit: 500Mi

extraVolumeMounts:
  - name: tmp
    mountPath: /tmp
  - name: cache
    mountPath: /app/.cache

# =============================================================================
# Extra Environment Variables
# =============================================================================
extraEnv: []
  # - name: EXTRA_VAR
  #   value: "value"

extraEnvFrom: []
  # - configMapRef:
  #     name: extra-config
