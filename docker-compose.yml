# ==============================================================================
# LLM Gateway - Docker Compose (Full Stack)
# ==============================================================================
# Full stack local development with all services
# See docs/DEPLOYMENT_IMPLEMENTATION_PLAN.md Section 1.2.4 for implementation
# See docs/INTEGRATION_MAP.md for service configuration details
# ==============================================================================

version: "3.9"

services:
  # ============================================================================
  # Redis - Session Storage & Caching
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: llm-gateway-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    networks:
      - llm-network

  # ============================================================================
  # LLM Gateway - Main Service
  # ============================================================================
  llm-gateway:
    build:
      context: .
      dockerfile: deploy/docker/Dockerfile
    container_name: llm-gateway
    ports:
      - "8080:8080"
    environment:
      # Service Configuration
      LLM_GATEWAY_ENV: development
      LLM_GATEWAY_PORT: "8080"
      LLM_GATEWAY_LOG_LEVEL: DEBUG
      LLM_GATEWAY_WORKERS: "2"
      
      # Redis Configuration
      LLM_GATEWAY_REDIS_URL: redis://redis:6379
      
      # Service Discovery (per INTEGRATION_MAP.md)
      LLM_GATEWAY_SEMANTIC_SEARCH_URL: http://semantic-search:8081
      LLM_GATEWAY_AI_AGENTS_URL: http://ai-agents:8082
      
      # Provider Configuration (override with .env file)
      LLM_GATEWAY_DEFAULT_PROVIDER: anthropic
      LLM_GATEWAY_DEFAULT_MODEL: claude-3-sonnet-20240229
      
      # Rate Limiting
      LLM_GATEWAY_RATE_LIMIT_REQUESTS_PER_MINUTE: "60"
      
      # Session Configuration
      LLM_GATEWAY_SESSION_TTL_SECONDS: "3600"
    env_file:
      - .env  # For API keys (ANTHROPIC_API_KEY, OPENAI_API_KEY)
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - llm-network

# ==============================================================================
# Networks
# ==============================================================================
networks:
  llm-network:
    name: llm-network
    driver: bridge

# ==============================================================================
# Volumes
# ==============================================================================
volumes:
  redis-data:
    name: llm-gateway-redis-data
